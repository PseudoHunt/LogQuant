{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVGLZe6w9Rbe",
        "outputId": "4fba8d35-9263-4056-e765-b6caf704336c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dense Linear Layer Time: 0.000148 seconds per forward pass\n",
            "TuckerSparseLinear Time: 0.001060 seconds per forward pass\n",
            "Speedup Factor: 0.14x\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.sparse as sparse\n",
        "import time\n",
        "\n",
        "# ------------------------------\n",
        "# TuckerSparseLinear Definition\n",
        "# ------------------------------\n",
        "class TuckerSparseLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, rank, residual_sparsity):\n",
        "        super(TuckerSparseLinear, self).__init__()\n",
        "\n",
        "        # Tucker decomposition components\n",
        "        self.U1 = nn.Parameter(torch.randn(in_features, rank))  # Left factor\n",
        "        self.U2 = nn.Parameter(torch.randn(out_features, rank))  # Right factor\n",
        "        self.G = nn.Parameter(torch.randn(rank, rank))  # Core tensor\n",
        "\n",
        "        # Sparse residual (stored as sparse tensor)\n",
        "        residual_dense = torch.randn(in_features, out_features)\n",
        "        residual_dense[torch.rand_like(residual_dense) > residual_sparsity] = 0  # Sparsify\n",
        "        indices = residual_dense.nonzero(as_tuple=False).t()\n",
        "        values = residual_dense[indices[0], indices[1]]\n",
        "        self.R = sparse.FloatTensor(indices, values, torch.Size([in_features, out_features])).cuda()\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Tucker decomposition computation\n",
        "        Z = torch.matmul(X, self.U1)  # First projection\n",
        "        Z = torch.matmul(Z, self.G)  # Core multiplication\n",
        "        Y_tucker = torch.matmul(Z, self.U2.T)  # Project back\n",
        "\n",
        "        # Sparse residual addition (sparse-dense matmul)\n",
        "        #Y_residual = torch.sparse.mm(self.R.t(), X.t()).T  # Compute X @ R efficiently\n",
        "        Y_residual = torch.sparse.mm( X,self.R )\n",
        "        return Y_tucker + Y_residual\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Benchmarking Function\n",
        "# ------------------------------\n",
        "def benchmark_layer(layer, X, n_iters=100):\n",
        "    layer.eval()  # Set to inference mode\n",
        "    torch.cuda.synchronize()\n",
        "    start_time = time.time()\n",
        "\n",
        "    for _ in range(n_iters):\n",
        "        with torch.no_grad():\n",
        "            _ = layer(X)  # Forward pass\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    end_time = time.time()\n",
        "\n",
        "    avg_time = (end_time - start_time) / n_iters\n",
        "    return avg_time\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Test Parameters\n",
        "# ------------------------------\n",
        "in_features = 512\n",
        "out_features = 256\n",
        "rank = 64  # Tucker decomposition rank\n",
        "residual_sparsity = 0.1  # 90% sparsity in residual\n",
        "batch_size = 1000\n",
        "n_iters = 100  # Number of iterations for benchmarking\n",
        "\n",
        "# Generate random input\n",
        "X = torch.randn(batch_size, in_features).cuda()\n",
        "\n",
        "# Define models\n",
        "dense_layer = nn.Linear(in_features, out_features).cuda()\n",
        "tucker_sparse_layer = TuckerSparseLinear(in_features, out_features, rank, residual_sparsity).cuda()\n",
        "\n",
        "# ------------------------------\n",
        "# Run Benchmark\n",
        "# ------------------------------\n",
        "dense_time = benchmark_layer(dense_layer, X, n_iters)\n",
        "tucker_sparse_time = benchmark_layer(tucker_sparse_layer, X, n_iters)\n",
        "\n",
        "# ------------------------------\n",
        "# Results\n",
        "# ------------------------------\n",
        "print(f\"Dense Linear Layer Time: {dense_time:.6f} seconds per forward pass\")\n",
        "print(f\"TuckerSparseLinear Time: {tucker_sparse_time:.6f} seconds per forward pass\")\n",
        "speedup = dense_time / tucker_sparse_time\n",
        "print(f\"Speedup Factor: {speedup:.2f}x\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E1L6kGnaBFAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "\n",
        "# Optimized TuckerSparseLinear Layer\n",
        "class TuckerSparseLinearOptimized(nn.Module):\n",
        "    def __init__(self, in_features, out_features, rank, residual_sparsity):\n",
        "        super(TuckerSparseLinearOptimized, self).__init__()\n",
        "\n",
        "        # Tucker decomposition components (Low-rank factors)\n",
        "        self.U1 = nn.Parameter(torch.randn(in_features, rank))  # Left factor\n",
        "        self.G = nn.Parameter(torch.randn(rank, rank))  # Core tensor\n",
        "        self.U2 = nn.Parameter(torch.randn(out_features, rank))  # Right factor\n",
        "\n",
        "        # Sparse residual matrix in CSR format\n",
        "        residual_dense = torch.randn(in_features, out_features)\n",
        "        residual_dense[torch.rand_like(residual_dense) > residual_sparsity] = 0  # Sparsify\n",
        "\n",
        "        # Convert to CSR format\n",
        "        self.R = torch.sparse_csr_tensor(\n",
        "            residual_dense.to_sparse_csr().crow_indices(),\n",
        "            residual_dense.to_sparse_csr().col_indices(),\n",
        "            residual_dense.to_sparse_csr().values(),\n",
        "            size=(in_features, out_features)\n",
        "        ).cuda()\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Optimized Tucker decomposition\n",
        "        Z = torch.matmul(X, self.U1)  # X @ U1 (Project input)\n",
        "        Z = torch.matmul(Z, self.G)   # Z @ G (Apply core tensor)\n",
        "        Y_tucker = torch.matmul(Z, self.U2.T)  # Project back with U2^T\n",
        "\n",
        "        # Optimized sparse-dense multiplication using CSR format\n",
        "        Y_residual = torch.sparse.mm(X,self.R)  # Efficient matmul\n",
        "\n",
        "        return Y_tucker + Y_residual\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Benchmarking Function\n",
        "# ------------------------------\n",
        "def benchmark_layer(layer, X, n_iters=100):\n",
        "    layer.eval()\n",
        "    torch.cuda.synchronize()\n",
        "    start_time = time.time()\n",
        "\n",
        "    for _ in range(n_iters):\n",
        "        with torch.no_grad():\n",
        "            _ = layer(X)  # Forward pass\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    end_time = time.time()\n",
        "\n",
        "    avg_time = (end_time - start_time) / n_iters\n",
        "    return avg_time\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Test Parameters\n",
        "# ------------------------------\n",
        "in_features = 512\n",
        "out_features = 256\n",
        "rank = 64  # Tucker decomposition rank\n",
        "residual_sparsity = 0.1  # 90% sparsity in residual\n",
        "batch_size = 1000\n",
        "n_iters = 100  # Number of iterations for benchmarking\n",
        "\n",
        "# Generate random input\n",
        "X = torch.randn(batch_size, in_features).cuda()\n",
        "\n",
        "# Define models\n",
        "dense_layer = nn.Linear(in_features, out_features).cuda()\n",
        "tucker_sparse_layer = TuckerSparseLinearOptimized(in_features, out_features, rank, residual_sparsity).cuda()\n",
        "\n",
        "# ------------------------------\n",
        "# Run Benchmark\n",
        "# ------------------------------\n",
        "dense_time = benchmark_layer(dense_layer, X, n_iters)\n",
        "tucker_sparse_time = benchmark_layer(tucker_sparse_layer, X, n_iters)\n",
        "\n",
        "# ------------------------------\n",
        "# Results\n",
        "# ------------------------------\n",
        "print(f\"Dense Linear Layer Time: {dense_time:.6f} seconds per forward pass\")\n",
        "print(f\"Optimized TuckerSparseLinear Time: {tucker_sparse_time:.6f} seconds per forward pass\")\n",
        "speedup = dense_time / tucker_sparse_time\n",
        "print(f\"Speedup Factor: {speedup:.2f}x ðŸš€\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hNKwvD39U9y",
        "outputId": "f88cc634-a8df-4ad9-b4d0-be89e8468205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dense Linear Layer Time: 0.000150 seconds per forward pass\n",
            "Optimized TuckerSparseLinear Time: 0.001681 seconds per forward pass\n",
            "Speedup Factor: 0.09x ðŸš€\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "\n",
        "class TuckerSparseLinearFast(nn.Module):\n",
        "    def __init__(self, in_features, out_features, rank, residual_sparsity):\n",
        "        super(TuckerSparseLinearFast, self).__init__()\n",
        "\n",
        "        # Tucker decomposition components\n",
        "        self.U1 = nn.Parameter(torch.randn(in_features, rank))  # Left factor\n",
        "        self.G = nn.Parameter(torch.randn(rank, rank))  # Core tensor\n",
        "        self.U2 = nn.Parameter(torch.randn(out_features, rank))  # Right factor\n",
        "\n",
        "        # Sparse residual (but convert to dense for inference)\n",
        "        residual_dense = torch.randn(in_features, out_features)\n",
        "        residual_dense[torch.rand_like(residual_dense) > residual_sparsity] = 0  # Sparsify\n",
        "\n",
        "        # Store residual in sparse format for training, but dense for inference\n",
        "        self.register_buffer('R_dense', residual_dense)  # Convert to dense tensor for fast GPU execution\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Optimized Tucker decomposition computation (fused)\n",
        "        Z = torch.matmul(X, self.U1)  # First projection\n",
        "        Z = torch.matmul(Z, self.G)   # Core multiplication\n",
        "        Y_tucker = torch.matmul(Z, self.U2.T)  # Project back\n",
        "\n",
        "        # Replace sparse multiplication with dense-dense matmul\n",
        "        Y_residual = torch.matmul(X, self.R_dense)  # MUCH faster on GPU!\n",
        "\n",
        "        return Y_tucker + Y_residual\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Benchmarking Function\n",
        "# ------------------------------\n",
        "def benchmark_layer(layer, X, n_iters=100):\n",
        "    layer.eval()\n",
        "    torch.cuda.synchronize()\n",
        "    start_time = time.time()\n",
        "\n",
        "    for _ in range(n_iters):\n",
        "        with torch.no_grad():\n",
        "            _ = layer(X)  # Forward pass\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    end_time = time.time()\n",
        "\n",
        "    avg_time = (end_time - start_time) / n_iters\n",
        "    return avg_time\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Test Parameters\n",
        "# ------------------------------\n",
        "in_features = 512\n",
        "out_features = 256\n",
        "rank = 64  # Tucker decomposition rank\n",
        "residual_sparsity = 0.9  # 90% sparsity in residual\n",
        "batch_size = 1000\n",
        "n_iters = 100  # Number of iterations for benchmarking\n",
        "\n",
        "# Generate random input\n",
        "X = torch.randn(batch_size, in_features).cuda()\n",
        "\n",
        "# Define models\n",
        "dense_layer = nn.Linear(in_features, out_features).cuda()\n",
        "tucker_sparse_layer = TuckerSparseLinearFast(in_features, out_features, rank, residual_sparsity).cuda()\n",
        "\n",
        "# ------------------------------\n",
        "# Run Benchmark\n",
        "# ------------------------------\n",
        "dense_time = benchmark_layer(dense_layer, X, n_iters)\n",
        "tucker_sparse_time = benchmark_layer(tucker_sparse_layer, X, n_iters)\n",
        "\n",
        "# ------------------------------\n",
        "# Results\n",
        "# ------------------------------\n",
        "print(f\"Dense Linear Layer Time: {dense_time:.6f} seconds per forward pass\")\n",
        "print(f\"Fast TuckerSparseLinear Time: {tucker_sparse_time:.6f} seconds per forward pass\")\n",
        "speedup = dense_time / tucker_sparse_time\n",
        "print(f\"Speedup Factor: {speedup:.2f}x ðŸš€\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v5vBXsGByhx",
        "outputId": "6f4f81b4-20a5-4475-d875-c0cc634c8ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dense Linear Layer Time: 0.000149 seconds per forward pass\n",
            "Fast TuckerSparseLinear Time: 0.000242 seconds per forward pass\n",
            "Speedup Factor: 0.61x ðŸš€\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.sparse as sparse\n",
        "\n",
        "class FastTuckerSparseLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, rank, residual_sparsity):\n",
        "        super(FastTuckerSparseLinear, self).__init__()\n",
        "\n",
        "        # Tucker factors (FP16 for Tensor Cores)\n",
        "        self.U1 = nn.Parameter(torch.randn(in_features, rank, dtype=torch.float16).cuda())\n",
        "        self.U2 = nn.Parameter(torch.randn(out_features, rank, dtype=torch.float16).cuda())\n",
        "        self.G = nn.Parameter(torch.randn(rank, rank, dtype=torch.float16).cuda())\n",
        "\n",
        "        # Precompute fused Tucker matrix (U1 @ G @ U2^T)\n",
        "        with torch.no_grad():\n",
        "            fused_tucker = torch.matmul(\n",
        "                torch.matmul(self.U1.float(), self.G.float()),  # FP32 for stability\n",
        "                self.U2.T.float()\n",
        "            ).to(torch.float16)  # Cast back to FP16\n",
        "        self.register_buffer(\"fused_tucker\", fused_tucker)\n",
        "\n",
        "        # Sparse residual (CSR format)\n",
        "        residual_dense = torch.randn(in_features, out_features, dtype=torch.float16).cuda()\n",
        "        mask = torch.rand_like(residual_dense) > residual_sparsity\n",
        "        residual_dense[mask] = 0\n",
        "        self.R = residual_dense.to_sparse_csr().cuda()\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Tucker path (single matmul)\n",
        "        Y_tucker = torch.matmul(X, self.fused_tucker)\n",
        "\n",
        "        # Sparse residual (batched matmul)\n",
        "        Y_residual = torch.sparse.mm(X, self.R, \"csr\")  # CSR format optimized\n",
        "        return Y_tucker + Y_residual\n",
        "\n",
        "def benchmark_layer(layer, X, n_iters=100):\n",
        "    layer.eval()\n",
        "    torch.cuda.synchronize()\n",
        "    start = time.time()\n",
        "    for _ in range(n_iters):\n",
        "        with torch.no_grad():\n",
        "            if(layer == dense_layer):\n",
        "              _ = layer(X)\n",
        "            else:\n",
        "              _ = layer(X.half() if layer.fused_tucker.dtype == torch.float16 else X)\n",
        "    torch.cuda.synchronize()\n",
        "    return (time.time() - start) / n_iters\n",
        "\n",
        "# Test Parameters\n",
        "in_features = 512\n",
        "out_features = 256\n",
        "rank = 64\n",
        "residual_sparsity = 0.95  # Increased from 0.9\n",
        "batch_size = 1000\n",
        "\n",
        "# FP16 Input\n",
        "X = torch.randn(batch_size, in_features).cuda().half()\n",
        "\n",
        "# Models\n",
        "dense_layer = nn.Linear(in_features, out_features).cuda().half()\n",
        "fast_tucker_layer = FastTuckerSparseLinear(in_features, out_features, rank, residual_sparsity)\n",
        "\n",
        "# Benchmark\n",
        "dense_time = benchmark_layer(dense_layer, X)\n",
        "fast_tucker_time = benchmark_layer(fast_tucker_layer, X)\n",
        "\n",
        "print(f\"Dense Time: {dense_time:.6f}s\")\n",
        "print(f\"FastTucker Time: {fast_tucker_time:.6f}s\")\n",
        "print(f\"Speedup: {dense_time / fast_tucker_time:.2f}x\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yewlJZuZCkrW",
        "outputId": "1edcb4be-5f7c-4865-bca5-6d7285c877d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "Could not run 'aten::_sparse_mm_reduce_impl' with arguments from the 'SparseCsrCUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_sparse_mm_reduce_impl' is only available for these backends: [Meta, SparseCsrCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at ../aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nSparseCsrCPU: registered at aten/src/ATen/RegisterSparseCsrCPU.cpp:1154 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:96 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradMTIA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:14885 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:321 [backend fallback]\nAutocastXPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:463 [backend fallback]\nAutocastMPS: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:157 [backend fallback]\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-244c82e63afc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Benchmark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mdense_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbenchmark_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mfast_tucker_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbenchmark_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfast_tucker_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dense Time: {dense_time:.6f}s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-244c82e63afc>\u001b[0m in \u001b[0;36mbenchmark_layer\u001b[0;34m(layer, X, n_iters)\u001b[0m\n\u001b[1;32m     43\u001b[0m               \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m               \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfused_tucker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_iters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-244c82e63afc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Sparse residual (batched matmul)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mY_residual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# CSR format optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mY_tucker\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mY_residual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'aten::_sparse_mm_reduce_impl' with arguments from the 'SparseCsrCUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_sparse_mm_reduce_impl' is only available for these backends: [Meta, SparseCsrCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at ../aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nSparseCsrCPU: registered at aten/src/ATen/RegisterSparseCsrCPU.cpp:1154 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:96 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradMTIA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:19529 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:14885 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:321 [backend fallback]\nAutocastXPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:463 [backend fallback]\nAutocastMPS: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:157 [backend fallback]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def compute_memory(model):\n",
        "    total_memory = 0\n",
        "    for param in model.parameters():\n",
        "        total_memory += param.numel() * param.element_size()  # numel() gives number of elements\n",
        "    return total_memory  # Memory in bytes\n",
        "\n",
        "# Dense Linear Layer\n",
        "dense_layer = nn.Linear(512, 256).cuda()\n",
        "dense_memory = compute_memory(dense_layer)\n",
        "\n",
        "# Optimized TuckerSparseLinear\n",
        "class TuckerSparseLinearFast(nn.Module):\n",
        "    def __init__(self, in_features, out_features, rank, residual_sparsity):\n",
        "        super(TuckerSparseLinearFast, self).__init__()\n",
        "        self.U1 = nn.Parameter(torch.randn(in_features, rank))  # Left factor\n",
        "        self.G = nn.Parameter(torch.randn(rank, rank))  # Core tensor\n",
        "        self.U2 = nn.Parameter(torch.randn(out_features, rank))  # Right factor\n",
        "\n",
        "        # Sparse residual (stored as dense for inference)\n",
        "        residual_dense = torch.randn(in_features, out_features)\n",
        "        residual_dense[torch.rand_like(residual_dense) > residual_sparsity] = 0  # Sparsify\n",
        "        self.register_buffer('R_dense', residual_dense)\n",
        "\n",
        "    def forward(self, X):\n",
        "        Z = torch.matmul(X, self.U1)  # First projection\n",
        "        Z = torch.matmul(Z, self.G)   # Core multiplication\n",
        "        Y_tucker = torch.matmul(Z, self.U2.T)  # Project back\n",
        "        Y_residual = torch.matmul(X, self.R_dense)  # Efficient dense-dense matmul\n",
        "        return Y_tucker + Y_residual\n",
        "\n",
        "tucker_layer = TuckerSparseLinearFast(512, 256, rank=64, residual_sparsity=0.5).cuda()\n",
        "tucker_memory = compute_memory(tucker_layer)\n",
        "\n",
        "# Compute memory reduction percentage\n",
        "memory_reduction = (1 - (tucker_memory / dense_memory)) * 100\n",
        "\n",
        "print(f\"Dense Layer Memory Usage: {dense_memory / 1024:.2f} KB\")\n",
        "print(f\"TuckerSparseLinear Memory Usage: {tucker_memory / 1024:.2f} KB\")\n",
        "print(f\"Memory Reduction: {memory_reduction:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03oPV8C6Da-j",
        "outputId": "07f804e0-a473-4bbc-f5e0-0e4f24b94fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dense Layer Memory Usage: 513.00 KB\n",
            "TuckerSparseLinear Memory Usage: 208.00 KB\n",
            "Memory Reduction: 59.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "# Load MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "train_data = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST('./data', train=False, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1000, shuffle=False)\n",
        "\n",
        "# Original Model\n",
        "class OriginalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "# Train the original model\n",
        "def train_model(model, epochs=2):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "# Evaluate accuracy\n",
        "def test_model(model):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    return 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "# --- Vanilla Weight Clustering (Post-Training) ---\n",
        "def cluster_weights(weight, n_clusters=16):\n",
        "    # Flatten and cluster weights\n",
        "    weights_np = weight.detach().cpu().numpy().reshape(-1, 1)\n",
        "    kmeans = KMeans(n_clusters=n_clusters, n_init=10).fit(weights_np)\n",
        "    clustered_weights = torch.tensor(kmeans.cluster_centers_[kmeans.labels_].reshape(weight.shape),\n",
        "                                    dtype=weight.dtype, device=weight.device)\n",
        "    return clustered_weights, kmeans.cluster_centers_.flatten()\n",
        "\n",
        "# Replace fc1 weights with clustered weights\n",
        "original_model = OriginalModel()\n",
        "train_model(original_model)  # Train original model\n",
        "\n",
        "clustered_weights, centroids = cluster_weights(original_model.fc1.weight)\n",
        "original_model.fc1.weight.data = clustered_weights\n",
        "print(f\"Clustered Model Accuracy: {test_model(original_model):.2f}%\")\n",
        "\n",
        "# --- Scaled Uniform Quantization ---\n",
        "class ScaledQuantizer(nn.Module):\n",
        "    def __init__(self, centroids, bits=8):\n",
        "        super().__init__()\n",
        "        self.scale = nn.Parameter(torch.tensor(1.0))  # Learnable scale\n",
        "        self.centroids = torch.tensor(centroids, dtype=torch.float32)\n",
        "        self.bins = 2 ** bits\n",
        "        self.bins = torch.linspace(self.centroids.min(), self.centroids.max(), self.bins)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Non-linear scaling: Learnable scale for better bin utilization\n",
        "        scaled_centroids = self.centroids * self.scale\n",
        "        # Quantize to nearest bin\n",
        "        quantized = torch.bucketize(scaled_centroids, self.bins)\n",
        "        dequantized = self.bins[quantized] / self.scale\n",
        "        return dequantized.to(x.device)\n",
        "\n",
        "# Apply scaled quantization to clustered weights\n",
        "quantizer = ScaledQuantizer(centroids, bits=4)\n",
        "quantized_weights = quantizer(clustered_weights.cpu()).to(clustered_weights.device)\n",
        "original_model.fc1.weight.data = quantized_weights\n",
        "print(f\"Clustered + Quantized Model Accuracy: {test_model(original_model):.2f}%\")\n",
        "\n",
        "# --- Compare with Original Model ---\n",
        "original_acc = test_model(original_model)\n",
        "print(f\"Original Model Accuracy: {original_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f_m72ZCxZ_TG",
        "outputId": "4f2a6078-0a17-4852-f644-2cdd12c7c872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:00<00:00, 16.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 501kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:00<00:00, 4.51MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 5.66MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Clustered Model Accuracy: 96.80%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat2 must be a matrix, got 1-D tensor",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e1d1bc9ffe55>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mquantized_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustered_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustered_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0moriginal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantized_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Clustered + Quantized Model Accuracy: {test_model(original_model):.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m# --- Compare with Original Model ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-e1d1bc9ffe55>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-e1d1bc9ffe55>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat2 must be a matrix, got 1-D tensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "# Load MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "train_data = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST('./data', train=False, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1000, shuffle=False)\n",
        "\n",
        "# Original Model\n",
        "class OriginalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "# Train the original model\n",
        "def train_model(model, epochs=2):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "# Evaluate accuracy\n",
        "def test_model(model):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    return 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "# --- Vanilla Weight Clustering (Post-Training) ---\n",
        "def cluster_weights(weight, n_clusters=16):\n",
        "    # Flatten and cluster weights\n",
        "    weights_np = weight.detach().cpu().numpy().reshape(-1, 1)\n",
        "    kmeans = KMeans(n_clusters=n_clusters, n_init=10).fit(weights_np)\n",
        "    clustered_weights = torch.tensor(kmeans.cluster_centers_[kmeans.labels_].reshape(weight.shape),\n",
        "                                    dtype=weight.dtype, device=weight.device)\n",
        "    return clustered_weights, kmeans.cluster_centers_.flatten()\n",
        "\n",
        "# Replace fc1 weights with clustered weights\n",
        "original_model = OriginalModel()\n",
        "train_model(original_model)  # Train original model\n",
        "\n",
        "# --- Compare with Original Model ---\n",
        "original_acc = test_model(original_model)\n",
        "print(f\"Original Model Accuracy: {original_acc:.2f}%\")\n",
        "\n",
        "clustered_weights, centroids = cluster_weights(original_model.fc1.weight)\n",
        "original_model.fc1.weight.data = clustered_weights\n",
        "print(f\"Clustered Model Accuracy: {test_model(original_model):.2f}%\")\n",
        "\n",
        "# --- Scaled Uniform Quantization (Fixed) ---\n",
        "class ScaledQuantizer(nn.Module):\n",
        "    def __init__(self, bits=8):\n",
        "        super().__init__()\n",
        "        self.scale = nn.Parameter(torch.tensor(1.0))  # Learnable scale\n",
        "        self.bins = 2 ** bits\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input x: clustered weight matrix (2D)\n",
        "        # 1. Flatten and scale weights\n",
        "        original_shape = x.shape\n",
        "        x_flat = x.view(-1)\n",
        "        scaled = x_flat * self.scale\n",
        "\n",
        "        # 2. Create uniform bins based on scaled values\n",
        "        self.bins = torch.linspace(scaled.min().item(),\n",
        "                                 scaled.max().item(),\n",
        "                                 self.bins,\n",
        "                                 device=x.device)\n",
        "\n",
        "        # 3. Quantize and dequantize\n",
        "        quantized_indices = torch.bucketize(scaled, self.bins)\n",
        "        dequantized = self.bins[quantized_indices] / self.scale\n",
        "\n",
        "        # 4. Restore original shape\n",
        "        return dequantized.view(original_shape)\n",
        "\n",
        "# Apply to clustered weights\n",
        "quantizer = ScaledQuantizer(bits=4)\n",
        "quantized_weights = quantizer(clustered_weights)  # Preserves 2D shape\n",
        "original_model.fc1.weight.data = quantized_weights\n",
        "\n",
        "print(f\"Clustered + Quantized Model Accuracy: {test_model(original_model):.2f}%\")\n",
        "\n",
        "# --- Compare with Original Model ---\n",
        "original_acc = test_model(original_model)\n",
        "print(f\"Original Model Accuracy: {original_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9559ea51-1f1f-47e3-c8b0-cdde86966ed3",
        "id": "86xPXqPUbD6u"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Model Accuracy: 97.36%\n",
            "Clustered Model Accuracy: 97.31%\n",
            "Clustered + Quantized Model Accuracy: 97.10%\n",
            "Original Model Accuracy: 97.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MYY-huph73xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cj4B7tcCe4Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "centroids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU0IfvUFaAXA",
        "outputId": "57c2d7f8-c086-434f-c24d-2b2b442b94f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.01064064, -0.03667125,  0.09016854, -0.13849382, -0.01176928,\n",
              "        0.0330373 , -0.05315294, -0.21102199,  0.06497895, -0.07327051,\n",
              "       -0.02347448,  0.0464217 , -0.00038369,  0.13053863,  0.02162247,\n",
              "       -0.09958723], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'centroids' is your NumPy array of centroids\n",
        "plt.hist(centroids, bins=16)  # Adjust bins as needed\n",
        "plt.title(\"Distribution of Centroids\")\n",
        "plt.xlabel(\"Centroid Value\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "S7ULtMbqdRZb",
        "outputId": "e517fec5-e44c-45c8-f9b4-5f6d1c8547a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SigmoidQuantizer(nn.Module):\n",
        "    def __init__(self, bits=8):\n",
        "        super().__init__()\n",
        "        self.scale = nn.Parameter(torch.tensor(5.0))  # Learnable global scale\n",
        "        self.beta = nn.Parameter(torch.tensor(10.0))  # Learnable sigmoid steepness\n",
        "        self.bins = 2 ** bits\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input x: clustered weight matrix (2D)\n",
        "        original_shape = x.shape\n",
        "        x_flat = x.view(-1)\n",
        "\n",
        "        # Sigmoid-based scaling (emphasize near-zero values)\n",
        "        sigmoid_mask = torch.sigmoid(self.beta * torch.abs(x_flat))  # [0,1] mask\n",
        "        scaled = x_flat * (self.scale * sigmoid_mask)  # Non-linear scaling\n",
        "\n",
        "        # Create uniform bins based on scaled values\n",
        "        self.bins = torch.linspace(scaled.min().item(),\n",
        "                                 scaled.max().item(),\n",
        "                                 self.bins,\n",
        "                                 device=x.device)\n",
        "\n",
        "        # Quantize and dequantize\n",
        "        quantized_indices = torch.bucketize(scaled, self.bins)\n",
        "        dequantized = self.bins[quantized_indices] / (self.scale * sigmoid_mask)\n",
        "\n",
        "        return dequantized.view(original_shape)\n",
        "\n",
        "# --- Full Modified Workflow ---\n",
        "# Cluster weights (same as before)\n",
        "clustered_weights, centroids = cluster_weights(original_model.fc1.weight)\n",
        "\n",
        "# Apply sigmoid-based quantization\n",
        "quantizer = SigmoidQuantizer(bits=4)\n",
        "quantized_weights = quantizer(clustered_weights)\n",
        "original_model.fc1.weight.data = quantized_weights\n",
        "\n",
        "print(f\"Sigmoid-Scaled Quantized Accuracy: {test_model(original_model):.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ6hZZxBdzwx",
        "outputId": "8ff7f50b-3e5f-43b8-c3c6-bc601cca73f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (12) found smaller than n_clusters (16). Possibly due to duplicate points in X.\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sigmoid-Scaled Quantized Accuracy: 92.83%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Load MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "train_data = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST('./data', train=False, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1000, shuffle=False)\n",
        "\n",
        "# Original Model\n",
        "class OriginalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "# Train the original model\n",
        "def train_model(model, epochs=2):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "# Evaluate accuracy\n",
        "def test_model(model):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    return 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "# --- Vanilla Weight Clustering (Post-Training) ---\n",
        "def cluster_weights(weight, n_clusters=16):\n",
        "    weights_np = weight.detach().cpu().numpy().reshape(-1, 1)\n",
        "    kmeans = KMeans(n_clusters=n_clusters, n_init=10).fit(weights_np)\n",
        "    clustered_weights = torch.tensor(kmeans.cluster_centers_[kmeans.labels_].reshape(weight.shape),\n",
        "                                    dtype=weight.dtype, device=weight.device)\n",
        "    return clustered_weights, kmeans.cluster_centers_.flatten()\n",
        "\n",
        "# --- Sigmoid Quantizer with Learnable Parameters ---\n",
        "class SigmoidQuantizer(nn.Module):\n",
        "    def __init__(self, bits=4):\n",
        "        super().__init__()\n",
        "        self.scale = nn.Parameter(torch.tensor(5.0))  # Learnable global scale\n",
        "        self.beta = nn.Parameter(torch.tensor(10.0))  # Learnable sigmoid steepness\n",
        "        self.bits = bits\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input x: clustered weight matrix (2D)\n",
        "        original_shape = x.shape\n",
        "        x_flat = x.view(-1)\n",
        "\n",
        "        # Sigmoid-based scaling\n",
        "        sigmoid_mask = torch.sigmoid(self.beta * torch.abs(x_flat))  # [0,1]\n",
        "        scaled = x_flat * (self.scale * sigmoid_mask)\n",
        "\n",
        "        # Uniform quantization\n",
        "        bins = torch.linspace(scaled.min().item(), scaled.max().item(), 2 ** self.bits, device=x.device)\n",
        "        quantized_indices = torch.bucketize(scaled, bins)\n",
        "        dequantized = bins[quantized_indices] / (self.scale * sigmoid_mask)\n",
        "\n",
        "        return dequantized.view(original_shape)\n",
        "\n",
        "# --- Workflow ---\n",
        "# 1. Train original model\n",
        "original_model = OriginalModel()\n",
        "train_model(original_model)\n",
        "print(f\"Original Model Accuracy: {test_model(original_model):.2f}%\")\n",
        "\n",
        "# 2. Cluster weights and freeze\n",
        "clustered_weights, _ = cluster_weights(original_model.fc1.weight)\n",
        "original_model.fc1.weight.data = clustered_weights\n",
        "original_model.fc1.weight.requires_grad = False  # Freeze clustered weights\n",
        "print(f\"Clustered Model Accuracy: {test_model(original_model):.2f}%\")\n",
        "\n",
        "# 3. Attach SigmoidQuantizer to fc1\n",
        "sigmoid_quantizer = SigmoidQuantizer(bits=4)\n",
        "original_model.fc1.quantizer = sigmoid_quantizer\n",
        "\n",
        "# 4. Fine-tune quantizer parameters\n",
        "optimizer = optim.Adam(original_model.fc1.quantizer.parameters(), lr=0.01)  # Only quantizer params\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Fine-tuning loop\n",
        "original_model.train()\n",
        "for epoch in range(2):  # Short fine-tuning\n",
        "    for data, target in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Quantize weights dynamically during forward pass\n",
        "        quantized_weights = original_model.fc1.quantizer(original_model.fc1.weight)\n",
        "        output = F.linear(data.view(-1, 784), quantized_weights, original_model.fc1.bias)\n",
        "        output = F.relu(output)\n",
        "        output = original_model.fc2(output)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# 5. Test final accuracy\n",
        "print(f\"Clustered + Sigmoid-Quantized Accuracy: {test_model(original_model):.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdhkWiyhe5Xs",
        "outputId": "2253169b-d7cb-49b6-f951-85842a507c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Model Accuracy: 97.04%\n",
            "Clustered Model Accuracy: 96.97%\n",
            "Clustered + Sigmoid-Quantized Accuracy: 96.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorly as tl\n",
        "from tensorly.decomposition import tucker\n",
        "\n",
        "# Initialize\n",
        "ranks = [r1, r2, ..., rN]  # Initial low ranks\n",
        "core, factors = tucker(original_tensor, ranks)\n",
        "\n",
        "# Iteratively sparsify residual\n",
        "for _ in range(max_iter):\n",
        "    residual = original_tensor - tl.tucker_to_tensor(core, factors)\n",
        "    residual = threshold(residual, tau)  # Hard/soft thresholding\n",
        "    core, factors = tucker(original_tensor - residual, ranks)import tensorly as tl\n",
        "\n",
        "def threshold(residual_dense, tau):\n",
        "  residual_dense[residual_dense > tau] = 0"
      ],
      "metadata": {
        "id": "jxCJZqei75Bv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}